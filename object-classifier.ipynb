{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0020c91",
   "metadata": {},
   "source": [
    "# Object Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edcd763",
   "metadata": {},
   "source": [
    "## Process images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317d69c",
   "metadata": {},
   "source": [
    "### Extract data from .7z files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d659ca1",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "1. Download the dataset from the following link: https://www.kaggle.com/c/cifar-10\n",
    "2. Extract the dataset into a directory named `data`.\n",
    "3. Run this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d3cabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted successfully\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "dataset = ZipFile('data/cifar-10.zip')\n",
    "dataset.extractall(path='data')\n",
    "dataset.close()\n",
    "print(\"Dataset extracted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66491243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py7zr\n",
    "\n",
    "archive = py7zr.SevenZipFile('data/train.7z', mode='r')\n",
    "archive.extractall(path='data')\n",
    "archive.close()\n",
    "train_file_location='data/train'\n",
    "\n",
    "archive = py7zr.SevenZipFile('data/test.7z', mode='r')\n",
    "archive.extractall(path='data')\n",
    "archive.close()\n",
    "test_file_location='data/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d38b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90786678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(\"data/train\")\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b483bf8f",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef97988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_as_array(path):\n",
    "    try:\n",
    "        image = Image.open(path)\n",
    "        return np.array(image)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df = pd.read_csv('data/trainLabels.csv')\n",
    "df['image'] = df['id'].apply(lambda x: get_image_as_array(f'data/train/{x}.png'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21c32e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frog</td>\n",
       "      <td>[[[59, 62, 63], [43, 46, 45], [50, 48, 43], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>truck</td>\n",
       "      <td>[[[154, 177, 187], [126, 137, 136], [105, 104,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>truck</td>\n",
       "      <td>[[[255, 255, 255], [253, 253, 253], [253, 253,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>deer</td>\n",
       "      <td>[[[28, 25, 10], [37, 34, 19], [38, 35, 20], [4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>automobile</td>\n",
       "      <td>[[[170, 180, 198], [168, 178, 196], [177, 185,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       label                                              image\n",
       "0   1        frog  [[[59, 62, 63], [43, 46, 45], [50, 48, 43], [6...\n",
       "1   2       truck  [[[154, 177, 187], [126, 137, 136], [105, 104,...\n",
       "2   3       truck  [[[255, 255, 255], [253, 253, 253], [253, 253,...\n",
       "3   4        deer  [[[28, 25, 10], [37, 34, 19], [38, 35, 20], [4...\n",
       "4   5  automobile  [[[170, 180, 198], [168, 178, 196], [177, 185,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb04147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True, subset=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fec8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68663c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n",
      " 'airplane']\n"
     ]
    }
   ],
   "source": [
    "object_classes = df['label'].unique()\n",
    "print(object_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d429fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "frog          5000\n",
      "truck         5000\n",
      "deer          5000\n",
      "automobile    5000\n",
      "bird          5000\n",
      "horse         5000\n",
      "ship          5000\n",
      "cat           5000\n",
      "dog           5000\n",
      "airplane      5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For reference\n",
    "entries_per_class = df['label'].value_counts()\n",
    "print(entries_per_class) # no need to standardize or scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c902e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frog': 0, 'truck': 1, 'deer': 2, 'automobile': 3, 'bird': 4, 'horse': 5, 'ship': 6, 'cat': 7, 'dog': 8, 'airplane': 9}\n"
     ]
    }
   ],
   "source": [
    "# labels_dictionary = dict(enumerate(object_classes))\n",
    "# print(labels_dictionary)\n",
    "labels_map = {}\n",
    "for index, item in enumerate(object_classes):\n",
    "    labels_map[item] = index\n",
    "\n",
    "print(labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59ff25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map(labels_map)\n",
    "df['image'] = df['image']/255\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "966d05fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3)\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "num_rows_80_percent = int(len(df) * 0.8)\n",
    "\n",
    "train = df.iloc[:num_rows_80_percent]\n",
    "test = df.iloc[num_rows_80_percent:]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e88a4440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.23137254901960785, 0.24313725490196078, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[0.6039215686274509, 0.6941176470588235, 0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [0.9921568627450981, 0.9921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[[[0.10980392156862745, 0.09803921568627451, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[[[0.6666666666666666, 0.7058823529411765, 0.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              image\n",
       "0   1      0  [[[0.23137254901960785, 0.24313725490196078, 0...\n",
       "1   2      1  [[[0.6039215686274509, 0.6941176470588235, 0.7...\n",
       "2   3      1  [[[1.0, 1.0, 1.0], [0.9921568627450981, 0.9921...\n",
       "3   4      2  [[[0.10980392156862745, 0.09803921568627451, 0...\n",
       "4   5      3  [[[0.6666666666666666, 0.7058823529411765, 0.7..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca8b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['image']\n",
    "y_train = train['label']\n",
    "\n",
    "X_test = test['image']\n",
    "y_test = test['label']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64192136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (40000, 32, 32, 3)\n",
      "y_train.shape:  (40000,)\n",
      "X_test.shape:  (10000, 32, 32, 3)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack(X_train).astype(\"float32\")   # shape: (N, 32, 32, 3)\n",
    "X_test  = np.stack(X_test).astype(\"float32\")\n",
    "\n",
    "y_train = np.array(y_train, dtype=\"int32\")      # shape: (N,)\n",
    "y_test  = np.array(y_test, dtype=\"int32\")\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d5ae4",
   "metadata": {},
   "source": [
    "## Create Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8d084",
   "metadata": {},
   "source": [
    "We shall create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f2dc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ansinha/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad590b",
   "metadata": {},
   "source": [
    "#### Setting up layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24f9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = len(object_classes)\n",
    "\n",
    "#setting up layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Flatten()(inputs)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(num_of_classes, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c652dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', # The data is not one hot encoded\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "957a0416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.2449 - loss: 2.0717 - val_accuracy: 0.3244 - val_loss: 1.9064\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.3469 - loss: 1.8245 - val_accuracy: 0.3735 - val_loss: 1.7683\n",
      "Epoch 3/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.3716 - loss: 1.7528 - val_accuracy: 0.3823 - val_loss: 1.7360\n",
      "Epoch 4/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.3768 - loss: 1.7350 - val_accuracy: 0.3681 - val_loss: 1.7610\n",
      "Epoch 5/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 0.3921 - loss: 1.6986 - val_accuracy: 0.3853 - val_loss: 1.7352\n",
      "Epoch 6/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.3992 - loss: 1.6756 - val_accuracy: 0.3835 - val_loss: 1.7394\n",
      "Epoch 7/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4048 - loss: 1.6711 - val_accuracy: 0.3695 - val_loss: 1.7680\n",
      "Epoch 8/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4064 - loss: 1.6546 - val_accuracy: 0.3934 - val_loss: 1.7059\n",
      "Epoch 9/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.4008 - loss: 1.6539 - val_accuracy: 0.3887 - val_loss: 1.7262\n",
      "Epoch 10/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4121 - loss: 1.6361 - val_accuracy: 0.3801 - val_loss: 1.7553\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb71f6",
   "metadata": {},
   "source": [
    "We can see that the accuracy of the model is really low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac50443",
   "metadata": {},
   "source": [
    "## Using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97b15fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.callbacks.history.History object at 0x38a3fb4c0>\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3bdc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, models, layers, optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec771316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "convolutional_base = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43793373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(convolutional_base) #makes sure all the processed values are normalized\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) # to prevent overfitting\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_of_classes, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6639e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e86b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4197s\u001b[0m 4s/step - accuracy: 0.2461 - loss: 2.2264 - val_accuracy: 0.6595 - val_loss: 1.1433\n",
      "Epoch 2/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3974s\u001b[0m 4s/step - accuracy: 0.5240 - loss: 1.4019 - val_accuracy: 0.8450 - val_loss: 0.5678\n",
      "Epoch 3/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3677s\u001b[0m 3s/step - accuracy: 0.6806 - loss: 0.9753 - val_accuracy: 0.8928 - val_loss: 0.3875\n",
      "Epoch 4/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3704s\u001b[0m 3s/step - accuracy: 0.7912 - loss: 0.6614 - val_accuracy: 0.9087 - val_loss: 0.3913\n",
      "Epoch 5/5\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3667s\u001b[0m 3s/step - accuracy: 0.8560 - loss: 0.4837 - val_accuracy: 0.9162 - val_loss: 0.4114\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,  validation_split=0.1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48739ccf",
   "metadata": {},
   "source": [
    "## Building a Predictive System\n",
    "Upload an image to classify using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc47cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ed410ec6b2458fb2b0885add4409e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.png,.jpg,.jpeg', description='Upload image'), Button(button_style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload and predict on a single image (32x32x3 normalized)\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Build inverse label map using existing `labels_map`\n",
    "try:\n",
    "    inv_labels_map = {v: k for k, v in labels_map.items()}\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"labels_map is not defined above. Please run the data prep cells first.\")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.png,.jpg,.jpeg',\n",
    "    multiple=False,\n",
    "    description='Upload image'\n",
    ")\n",
    "\n",
    "predict_btn = widgets.Button(\n",
    "    description='Predict',\n",
    "    button_style='primary',\n",
    "    tooltip='Run prediction on the uploaded image'\n",
    ")\n",
    "\n",
    "img_preview = widgets.Image(format='png')\n",
    "\n",
    "\n",
    "def preprocess_image(img: Image.Image) -> np.ndarray:\n",
    "    # Ensure RGB, resize to 32x32, normalize to [0,1], add batch dim\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((32, 32))\n",
    "    arr = np.array(img).astype('float32') / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def _get_uploaded_content(upload_widget: widgets.FileUpload):\n",
    "    v = upload_widget.value\n",
    "    # ipywidgets <8: dict-like {filename: {content: bytes, ...}}\n",
    "    if isinstance(v, dict):\n",
    "        first = next(iter(v.values()))\n",
    "        return first.get('content', None)\n",
    "    # ipywidgets >=8: tuple/list of UploadedFile (dict-like or object with .content)\n",
    "    if isinstance(v, (tuple, list)) and len(v) > 0:\n",
    "        first = v[0]\n",
    "        if isinstance(first, dict):\n",
    "            return first.get('content', None)\n",
    "        # Bunch/SimpleNamespace-like with attribute access\n",
    "        return getattr(first, 'content', None)\n",
    "    return None\n",
    "\n",
    "\n",
    "def on_predict_clicked(_):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if not uploader.value:\n",
    "            print('Please upload an image first.')\n",
    "            return\n",
    "        file_content = _get_uploaded_content(uploader)\n",
    "        if file_content is None:\n",
    "            print('Could not read uploaded file content. Please try another image.')\n",
    "            return\n",
    "        try:\n",
    "            pil_img = Image.open(io.BytesIO(file_content))\n",
    "        except Exception as e:\n",
    "            print('Failed to read image:', e)\n",
    "            return\n",
    "\n",
    "        # Show preview\n",
    "        display(pil_img)\n",
    "\n",
    "        # Preprocess\n",
    "        x = preprocess_image(pil_img)\n",
    "\n",
    "        # Ensure model is available\n",
    "        try:\n",
    "            m = model\n",
    "        except NameError:\n",
    "            print('Model is not defined. Please run the training cells first.')\n",
    "            return\n",
    "\n",
    "        # Predict\n",
    "        preds = m.predict(x)\n",
    "        if preds.ndim == 2 and preds.shape[0] == 1:\n",
    "            probs = preds[0]\n",
    "            pred_idx = int(np.argmax(probs))\n",
    "            pred_label = inv_labels_map.get(pred_idx, f'class_{pred_idx}')\n",
    "            confidence = float(probs[pred_idx])\n",
    "            print(f'Predicted: {pred_label} (confidence: {confidence:.3f})')\n",
    "        else:\n",
    "            print('Unexpected prediction output shape:', preds.shape)\n",
    "\n",
    "\n",
    "predict_btn.on_click(on_predict_clicked)\n",
    "\n",
    "ui = widgets.VBox([uploader, predict_btn, out])\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
